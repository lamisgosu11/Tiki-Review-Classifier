{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4814289",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "252a7838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7192e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import length\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, StringIndexer\n",
    "from pyspark.ml.classification import NaiveBayes, RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import lit\n",
    "from bs4 import BeautifulSoup\n",
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.sql.functions import when\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics, BinaryClassificationMetrics\n",
    "from datetime import datetime\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol \n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6235287",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Rating').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5dde6",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ace938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv(\"comment_final.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d0956ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------+\n",
      "|_c0|      processed_text|   class|\n",
      "+---+--------------------+--------+\n",
      "|  0|    rất_hài sản_phẩm|positive|\n",
      "|  1|                null|positive|\n",
      "|  2|sản_phẩm chất_lượ...|positive|\n",
      "|  3|sản_phẩm chất_lượ...|positive|\n",
      "|  4|sản_phẩm chất_lượ...|positive|\n",
      "|  5|cuộc_sống không_g...|positive|\n",
      "|  6|viết nhận_xét quá...|negative|\n",
      "|  7|hàng bị_lỗi màng ...|negative|\n",
      "|  8|sản_phẩm rất_tốt ...|positive|\n",
      "|  9|rất_hài sản_phẩm ...|positive|\n",
      "| 10|băng xài ổn lực c...|positive|\n",
      "| 11|sản_phẩm sản_phẩm...|negative|\n",
      "| 12|hàng băng bị_cắt sài|negative|\n",
      "| 13|mẫu_mã đẹp chất_l...|positive|\n",
      "| 14|sản_phẩm không_đú...|negative|\n",
      "| 15|hàng số_lượng đơn...|negative|\n",
      "| 16|không_nói đừng sả...|negative|\n",
      "| 17|dán vô rớt hoài v...|negative|\n",
      "| 18|                băng|positive|\n",
      "| 19|hàng đúng_hạn đón...|positive|\n",
      "+---+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.withColumn(\"class\", when(df1['class'] == \"negative\", \"negative\") \\\n",
    "      .when(df1['class'] == \"neutral\", \"negative\") \\\n",
    "      .otherwise(df1['class']))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75e2623f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196117"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f17376be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|   class| count|\n",
      "+--------+------+\n",
      "|positive|162683|\n",
      "|negative| 33434|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupby('class').count().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "587ebad0",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e53746f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumn('length', length(df2['processed_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ab983c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------+------+\n",
      "|_c0|      processed_text|   class|length|\n",
      "+---+--------------------+--------+------+\n",
      "|  0|    rất_hài sản_phẩm|positive|    16|\n",
      "|  1|                null|positive|  null|\n",
      "|  2|sản_phẩm chất_lượ...|positive|    85|\n",
      "|  3|sản_phẩm chất_lượ...|positive|    85|\n",
      "|  4|sản_phẩm chất_lượ...|positive|    85|\n",
      "+---+--------------------+--------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "594b92e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------------------+\n",
      "|   class|          avg(_c0)|       avg(length)|\n",
      "+--------+------------------+------------------+\n",
      "|positive| 96932.46765181365| 37.37301654406584|\n",
      "|negative|103534.61000777651|47.858651803036366|\n",
      "+--------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy('class').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68208f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df2.select('processed_text','class','length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7d0c9b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------+\n",
      "|      processed_text|   class|length|\n",
      "+--------------------+--------+------+\n",
      "|    rất_hài sản_phẩm|positive|    16|\n",
      "|                null|positive|  null|\n",
      "|sản_phẩm chất_lượ...|positive|    85|\n",
      "|sản_phẩm chất_lượ...|positive|    85|\n",
      "|sản_phẩm chất_lượ...|positive|    85|\n",
      "|cuộc_sống không_g...|positive|    70|\n",
      "|viết nhận_xét quá...|negative|   543|\n",
      "|hàng bị_lỗi màng ...|negative|    69|\n",
      "|sản_phẩm rất_tốt ...|positive|    57|\n",
      "|rất_hài sản_phẩm ...|positive|    23|\n",
      "|băng xài ổn lực c...|positive|    32|\n",
      "|sản_phẩm sản_phẩm...|negative|    90|\n",
      "|hàng băng bị_cắt sài|negative|    20|\n",
      "|mẫu_mã đẹp chất_l...|positive|    21|\n",
      "|sản_phẩm không_đú...|negative|    30|\n",
      "|hàng số_lượng đơn...|negative|    47|\n",
      "|không_nói đừng sả...|negative|    23|\n",
      "|dán vô rớt hoài v...|negative|    32|\n",
      "|                băng|positive|     4|\n",
      "|hàng đúng_hạn đón...|positive|    35|\n",
      "+--------------------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e317dc2",
   "metadata": {},
   "source": [
    "### Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6eefe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_data = data.filter(data['processed_text'].isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61c2e25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21720"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9121783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.filter(data['processed_text'].isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34ce89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null data\n",
    "data = data.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8380b755",
   "metadata": {},
   "source": [
    "### Duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7d272ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------+\n",
      "|      processed_text|   class|length|\n",
      "+--------------------+--------+------+\n",
      "|aaaaaaaaaaaaaaaaa...|positive|    41|\n",
      "|          abhhgycycy|negative|    10|\n",
      "|       ahas việt nam|positive|    13|\n",
      "|airpod máy case t...|positive|    31|\n",
      "|akg bàn rùi ổn_áp...|positive|    49|\n",
      "|      ammo dòng mack|positive|    14|\n",
      "|anessa hàng_xách ...|positive|   109|\n",
      "|anhận hàng rất_th...|positive|    79|\n",
      "|anker vọng bền lâ...|positive|    53|\n",
      "|     anten tốc_độ ul|positive|    15|\n",
      "|app báo hàng hàng...|positive|    57|\n",
      "|apply mặt bị_đen ...|positive|    80|\n",
      "|basss kết_nối hộp...|positive|    70|\n",
      "|bhjo bhuio bhtt b...|negative|    31|\n",
      "|bkav nhiêu rẻ tổn...|positive|    22|\n",
      "|boot android copy...|positive|    65|\n",
      "|bphone tích_hợp s...|positive|    85|\n",
      "|brush rẻ tốt khôn...|positive|    29|\n",
      "|bus hàng nhập_khẩ...|negative|    58|\n",
      "|buôn_bán mất_dạy ...|negative|    50|\n",
      "+--------------------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.dropDuplicates(['processed_text']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dc32248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------+\n",
      "|      processed_text|   class|length|\n",
      "+--------------------+--------+------+\n",
      "|    rất_hài sản_phẩm|positive|    16|\n",
      "|sản_phẩm chất_lượ...|positive|    85|\n",
      "|sản_phẩm chất_lượ...|positive|    85|\n",
      "|sản_phẩm chất_lượ...|positive|    85|\n",
      "|cuộc_sống không_g...|positive|    70|\n",
      "|viết nhận_xét quá...|negative|   543|\n",
      "|hàng bị_lỗi màng ...|negative|    69|\n",
      "|sản_phẩm rất_tốt ...|positive|    57|\n",
      "|rất_hài sản_phẩm ...|positive|    23|\n",
      "|băng xài ổn lực c...|positive|    32|\n",
      "|sản_phẩm sản_phẩm...|negative|    90|\n",
      "|hàng băng bị_cắt sài|negative|    20|\n",
      "|mẫu_mã đẹp chất_l...|positive|    21|\n",
      "|sản_phẩm không_đú...|negative|    30|\n",
      "|hàng số_lượng đơn...|negative|    47|\n",
      "|không_nói đừng sả...|negative|    23|\n",
      "|dán vô rớt hoài v...|negative|    32|\n",
      "|                băng|positive|     4|\n",
      "|hàng đúng_hạn đón...|positive|    35|\n",
      "|gọn bỏ_túi quảng_...|positive|    71|\n",
      "+--------------------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef64cc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174397"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62a8ca8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|   class| count|\n",
      "+--------+------+\n",
      "|positive|141924|\n",
      "|negative| 32473|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupby('class').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c9051d",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0b3c30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, explode, array, lit\n",
    "major_df = data.filter(col(\"class\") == 'positive')\n",
    "minor_df = data.filter(col(\"class\") == 'negative')\n",
    "ratio = int(major_df.count()/minor_df.count())\n",
    "print(\"ratio: {}\".format(ratio))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fd56152",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+------+\n",
      "|      processed_text|   class|length|\n",
      "+--------------------+--------+------+\n",
      "|cuộc_sống không_g...|positive|    70|\n",
      "|dính tốt tội bị_b...|positive|    33|\n",
      "|cũng_rất dính tội...|positive|    34|\n",
      "|          chất_lượng|positive|    10|\n",
      "|         độ dính tốt|positive|    11|\n",
      "|      máy hút xài ổn|positive|    14|\n",
      "|                 tốt|positive|     3|\n",
      "|                 bám|positive|     3|\n",
      "| sản_phẩm dính kháng|positive|    19|\n",
      "|   băng xài tốt hàng|positive|    17|\n",
      "|kích_thước quá_nh...|positive|    30|\n",
      "|         rất_rất tốt|positive|    11|\n",
      "|                dính|positive|     4|\n",
      "|        dất hài_lòng|positive|    12|\n",
      "|sản_phẩm chất_lượ...|positive|    85|\n",
      "|    hàng đóng_gói kỹ|positive|    16|\n",
      "|       hàng đóng_gói|positive|    13|\n",
      "|            hàng tốt|positive|     8|\n",
      "|sản_phẩm cụng gấp...|positive|    45|\n",
      "|                  ổn|positive|     2|\n",
      "+--------------------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampled_majority_df = major_df.sample(False, 1/ratio)\n",
    "combined_df_2 = sampled_majority_df.unionAll(minor_df)\n",
    "combined_df_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16a4cb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|   class|count|\n",
      "+--------+-----+\n",
      "|positive|35841|\n",
      "|negative|32473|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_df_2.groupby('class').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d85e9b",
   "metadata": {},
   "source": [
    "### Feature & Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "380fb963",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BsTextExtractor(Transformer, HasInputCol, HasOutputCol):\n",
    "    \n",
    "    @keyword_only\n",
    "    def __init__(self, inputCol=None, outputCol=None):\n",
    "        super(BsTextExtractor, self).__init__() \n",
    "        kwargs = self._input_kwargs \n",
    "        self.setParams(**kwargs)\n",
    "        \n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol=None, outputCol=None): \n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    def _transform(self, dataset):\n",
    "        def f(s):\n",
    "            cleaned_text = BeautifulSoup(s).text \n",
    "            return cleaned_text\n",
    "        t = StringType()\n",
    "        out_col = self.getOutputCol()\n",
    "        in_col = dataset[self.getInputCol()]\n",
    "        return dataset.withColumn(out_col, udf(f, t)(in_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c29777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_extractor = BsTextExtractor(inputCol=\"processed_text\", outputCol=\"cleaned_text\")\n",
    "tokenizer = Tokenizer(inputCol='cleaned_text', outputCol='token_text')\n",
    "stopremove= StopWordsRemover(inputCol='token_text', outputCol='stop_tokens')\n",
    "count_vec = CountVectorizer(inputCol='stop_tokens', outputCol='c_vec')\n",
    "idf = IDF(inputCol='c_vec', outputCol='tf_idf')\n",
    "ham_spam_to_num = StringIndexer(inputCol='class',outputCol='label', handleInvalid='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "680a2bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up = VectorAssembler(inputCols =['tf_idf','length'],\n",
    "                           outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c521930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_pipe = Pipeline(stages=[ham_spam_to_num,\n",
    "                                  text_extractor,\n",
    "                                  tokenizer,\n",
    "                                  stopremove,\n",
    "                                  count_vec,\n",
    "                                  idf,\n",
    "                                  clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1793128a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaner = data_prep_pipe.fit(combined_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eac4664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = cleaner.transform(combined_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd0c6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data.select('label','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f18affa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(18722,[266,482,9...|\n",
      "|  0.0|(18722,[2,45,106,...|\n",
      "|  0.0|(18722,[11,106,21...|\n",
      "|  0.0|(18722,[3,18721],...|\n",
      "|  0.0|(18722,[2,59,106,...|\n",
      "|  0.0|(18722,[7,9,12,46...|\n",
      "|  0.0|(18722,[2,18721],...|\n",
      "|  0.0|(18722,[358,18721...|\n",
      "|  0.0|(18722,[1,106,321...|\n",
      "|  0.0|(18722,[0,2,9,213...|\n",
      "|  0.0|(18722,[380,491,8...|\n",
      "|  0.0|(18722,[2,783,187...|\n",
      "|  0.0|(18722,[106,18721...|\n",
      "|  0.0|(18722,[51,16704,...|\n",
      "|  0.0|(18722,[0,1,3,10,...|\n",
      "|  0.0|(18722,[0,10,90,1...|\n",
      "|  0.0|(18722,[0,10,1872...|\n",
      "|  0.0|(18722,[0,2,18721...|\n",
      "|  0.0|(18722,[0,1,86,25...|\n",
      "|  0.0|(18722,[12,18721]...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91be6233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|35841|\n",
      "|  1.0|32473|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_data.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "232c8ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, test) = clean_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16d6c877",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82661486",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f256bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(18722,[0,1,2,3,4...|[-844.96257594922...|[1.0,3.1249067575...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,4...|[-879.67821422150...|[0.99999999980958...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,6...|[-177.76184014021...|[0.99999999908058...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,7...|[-1364.2679534025...|[1.0,5.4787251881...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,8...|[-543.52451854130...|[0.99999757602871...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,8...|[-611.78993982239...|[1.64882595820722...|       1.0|\n",
      "|  0.0|(18722,[0,1,2,3,1...|[-596.23661614330...|[4.91595059890390...|       1.0|\n",
      "|  0.0|(18722,[0,1,2,3,1...|[-762.93620611633...|[0.99999999999990...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,1...|[-479.44299123650...|[1.0,1.6365471699...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,1...|[-747.79795329377...|[0.99999999950215...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,1...|[-164.48176172329...|[0.99999999789049...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,1...|[-642.80170014809...|[0.00182285347245...|       1.0|\n",
      "|  0.0|(18722,[0,1,2,3,1...|[-139.45923720375...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,1...|[-136.69577311619...|[0.99998630386115...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,1...|[-255.60322098270...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,1...|[-751.43007332748...|[0.99999999998303...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,2...|[-200.46789202919...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,5...|[-533.24367059612...|[1.0,1.8267626005...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,6...|[-86.709542531940...|[0.99999998943347...|       0.0|\n",
      "|  0.0|(18722,[0,1,2,3,9...|[-328.13026915504...|[0.99999994967350...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "0:00:00\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes()\n",
    "prediction = nb.fit(train)\n",
    "test_results = prediction.transform(test)\n",
    "start_time = datetime.now()\n",
    "train_time = datetime.now() - start_time  \n",
    "test_results.show()\n",
    "print(train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dc9e443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       1.0| 1546|\n",
      "|  0.0|       0.0| 9190|\n",
      "|  1.0|       1.0| 7687|\n",
      "|  1.0|       0.0| 2050|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc491516",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0adb7738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Spark\\spark-3.4.0-bin-hadoop3\\python\\pyspark\\sql\\context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9190. 1546.]\n",
      " [2050. 7687.]]\n"
     ]
    }
   ],
   "source": [
    "#important: need to cast to float type, and order by prediction, else it won't work\n",
    "preds_and_labels = test_results.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "\n",
    "#select only prediction and label columns\n",
    "preds_and_labels = preds_and_labels.select(['prediction','label'])\n",
    "\n",
    "metrics = MulticlassMetrics(preds_and_labels.rdd.map(tuple))\n",
    "print(metrics.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1625e028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.8240348648449818\n"
     ]
    }
   ],
   "source": [
    "acc_eva = MulticlassClassificationEvaluator()\n",
    "acc = acc_eva.evaluate(test_results)\n",
    "print('Accuracy of model: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d2b16a",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c030040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression(maxIter=10, regParam=0.3)\n",
    "pre_lg = lg.fit(train)\n",
    "result_lg = pre_lg.transform(test)\n",
    "start_time = datetime.now()\n",
    "train_time = datetime.now() - start_time \n",
    "print(train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "886acbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  0.0|       1.0| 1111|\n",
      "|  0.0|       0.0| 9625|\n",
      "|  1.0|       1.0| 7552|\n",
      "|  1.0|       0.0| 2185|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_lg.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde2535f",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce68042b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Spark\\spark-3.4.0-bin-hadoop3\\python\\pyspark\\sql\\context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9625. 1111.]\n",
      " [2185. 7552.]]\n"
     ]
    }
   ],
   "source": [
    "#important: need to cast to float type, and order by prediction, else it won't work\n",
    "preds_and_labels_lg = result_lg.select(['prediction','label']).withColumn('label', F.col('label').cast(FloatType())).orderBy('prediction')\n",
    "\n",
    "#select only prediction and label columns\n",
    "preds_and_labels_lg = preds_and_labels_lg.select(['prediction','label'])\n",
    "\n",
    "metrics_lg = MulticlassMetrics(preds_and_labels_lg.rdd.map(tuple))\n",
    "print(metrics_lg.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7185057f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.8381434568804969\n"
     ]
    }
   ],
   "source": [
    "acc_eva_lg = MulticlassClassificationEvaluator()\n",
    "acc_lg = acc_eva_lg.evaluate(result_lg)\n",
    "print('Accuracy of model: {}'.format(acc_lg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1230a2",
   "metadata": {},
   "source": [
    "#### Nhận xét:\n",
    "- đối với việc sử dụng Pyspark, thời gian xử lý nhanh hơn, NB nhanh hơn về tốc độ xử lý so với logistic Regression\n",
    "- Tuy nhiên kết quả thì logistic lại tốt hơn về độ chính xác"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69384e11",
   "metadata": {},
   "source": [
    "##### Như vậy Pyspark cho kết quả tốt hơn cả về thời gian xử lý lân độ chính xác"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
